{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/J8g3rUjOiy3R1FGLEfPk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prakul/mongoDB_atlas_vector_search_sample/blob/main/MongoDB_Semantic_kernel_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N463Qo1DpXlr"
      },
      "outputs": [],
      "source": [
        "!python -m pip install semantic-kernel==0.3.14.dev openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "\n",
        "OPENAI_API_KEY = getpass.getpass(\"OpenAI API Key:\")\n",
        "MONGODB_ATLAS_CLUSTER_URI = getpass.getpass(\"MongoDB Atlas Cluster URI:\")\n",
        "MONGODB_ATLAS_VECTOR_SEARCH_INDEX=\"default\"\n",
        "MONGODB_DATABASE=\"semantic-kernel-test\"\n",
        "MONGODB_COLLECTION = \"test\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLMQF0ikp3Xq",
        "outputId": "d4a0d2db-671f-4ed7-d414-7d2af18e1be0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n",
            "MongoDB Atlas Cluster URI:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import semantic_kernel as sk\n",
        "\n",
        "kernel = sk.Kernel()"
      ],
      "metadata": {
        "id": "TbJ-GPOgq_4B"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register OpenAI model to the kernel\n"
      ],
      "metadata": {
        "id": "WUuyK6o-20yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from semantic_kernel.connectors.ai.open_ai import (OpenAIChatCompletion, OpenAITextEmbedding)\n",
        "\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "kernel.add_chat_service(\"chat-gpt\", OpenAIChatCompletion(\"gpt-3.5-turbo\", openai.api_key))\n",
        "kernel.add_text_embedding_generation_service(\"ada\", OpenAITextEmbedding(\"text-embedding-ada-002\", openai.api_key))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfSceKcCrBGQ",
        "outputId": "aa40c5b1-7c0b-4434-8fd2-75ca3b89440f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<semantic_kernel.kernel.Kernel at 0x7cd24ebf0490>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register MongoDBMemoryStore to the kernel\n",
        "\n"
      ],
      "metadata": {
        "id": "hTvbxMOUqWsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from semantic_kernel.connectors.memory.mongodb_atlas import MongoDBAtlasMemoryStore\n",
        "\n",
        "mongodb_atlas_store=MongoDBAtlasMemoryStore(index_name=MONGODB_ATLAS_VECTOR_SEARCH_INDEX, connection_string=MONGODB_ATLAS_CLUSTER_URI, database_name=MONGODB_DATABASE)\n",
        "kernel.register_memory_store(memory_store=mongodb_atlas_store)\n"
      ],
      "metadata": {
        "id": "x4fuIXfkqT3D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register TextMemorySkill"
      ],
      "metadata": {
        "id": "gZlfqMU2r7rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel.import_skill(sk.core_skills.TextMemorySkill())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdbNnoYkr8D-",
        "outputId": "46f2112e-7b52-46f6-c681-43303a2d1514"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'recall': <semantic_kernel.orchestration.sk_function.SKFunction at 0x7cd230259420>,\n",
              " 'save': <semantic_kernel.orchestration.sk_function.SKFunction at 0x7cd230288400>}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The need for RAG\n",
        "\n",
        "While LLM like OpenAI GPT-3.5 exhibit impressive wide range of skills. Being trained on the internet data it knows about a wide range of topics and can answer things accurately"
      ],
      "metadata": {
        "id": "tDYs7C6OsMaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrap your prompt in a function\n",
        "prompt = kernel.create_semantic_function(\"\"\"\n",
        "As a friendly AI Copilot answer the question: Did Albert Einstein like coffee?\n",
        "\"\"\")\n",
        "\n",
        "print(prompt())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifeOyQXAsLmb",
        "outputId": "b4e818bf-17a6-4212-ab9e-8545c4d690ed"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, Albert Einstein was known to enjoy coffee. He was often seen with a cup of coffee in his hand and would frequently visit cafes to discuss scientific ideas with his colleagues over a cup of coffee.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But LLMs also have a few limitations: they have a knowledge cutoff (Sep 2021 in case of OpenAI), and do not know about proprietary & personal data. They also have a tendency to hallucinate, that is they may confidently make up facts and provide answers that may seem to be accurate, but are actually incorrect. Here we can test an example to  demonstrate that:"
      ],
      "metadata": {
        "id": "Sf_VhxnI8xRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = kernel.create_semantic_function(\"\"\"\n",
        "As a friendly AI Copilot answer the question: Did we like coffee?\n",
        "\"\"\")\n",
        "\n",
        "print(prompt())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV87J3Om6np7",
        "outputId": "3286a1e0-fad1-48af-e36a-2b00bb9fb719"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As an AI, I don't have personal preferences or experiences, so I can't say whether \"we\" liked coffee or not. However, coffee is a popular beverage enjoyed by many people around the world. It has a distinct taste and aroma that some people find appealing, while others may not enjoy it as much. Ultimately, whether someone likes coffee or not is a subjective matter and varies from person to person.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will show how to augment the knowledge base of the LLM with proprietary data."
      ],
      "metadata": {
        "id": "4LH9W5qvDJTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def populate_memory(kernel: sk.Kernel) -> None:\n",
        "    # Add some documents to the semantic memory\n",
        "    await kernel.memory.save_information_async(\n",
        "        collection=MONGODB_COLLECTION, id=\"1\", text=\"We enjoy Starbucks\"\n",
        "    )\n",
        "    await kernel.memory.save_information_async(\n",
        "        collection=MONGODB_COLLECTION, id=\"2\", text=\"We are Associate Developer Advocates at MongoDB\"\n",
        "    )\n",
        "    await kernel.memory.save_information_async(\n",
        "        collection=MONGODB_COLLECTION, id=\"3\", text=\"We have great coworkers and we love our teams!\"\n",
        "    )\n",
        "    await kernel.memory.save_information_async(\n",
        "        collection=MONGODB_COLLECTION, id=\"4\", text=\"Our names are Anaiya and Tim\"\n",
        "    )\n",
        "    await kernel.memory.save_information_async(\n",
        "        collection=MONGODB_COLLECTION, id=\"5\", text=\"We have been to New York City and Dublin\"\n",
        "    )"
      ],
      "metadata": {
        "id": "TMjlektXCQR_"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Populating memory...aka adding in documents\")\n",
        "await populate_memory(kernel)\n",
        "print(kernel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgOZle35DT62",
        "outputId": "001fdc92-b965-4338-d515-c2cf276fa74b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating memory...aka adding in documents\n",
            "<semantic_kernel.kernel.Kernel object at 0x7cd24ebf0490>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## semantic search"
      ],
      "metadata": {
        "id": "92BnfdJ5G9Sv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "result = await kernel.memory.search_async(MONGODB_COLLECTION, 'Do we like coffee?')\n",
        "print(f\"Retreived document: {result[0].text}, {result[0].relevance}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hA28-5PG6t8",
        "outputId": "e85041c0-6f76-4fc2-aabc-3e6c999d8635"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retreived document: We enjoy Starbucks, 0.9399794936180115\n"
          ]
        }
      ]
    }
  ]
}